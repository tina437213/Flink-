# 2.2.7 状态TTL

TTL(Time-To-Live)

### 要小心无限期保留状态

使用无界键空间（key space），很容易意外地导致 Flink 保持无界状态，例如:

```java
DataStream<Tuple2<Long, Float>> maximums = input
    .keyBy(t -> t.f0)
    .reduce((t1, t2) -> 
      new Tuple2<>(t1.f0, Float.max(t1.f1, t2.f1)));
```

跟踪目前为止看到的每个键的最大值。

```scala
val counts: DataStream[(String, Int)] = input
  .keyBy(_._1)
  .mapWithState((in: (String, Int), count: Option[Int]) =>
    count match {
      case Some(c) => ( (in._1, c), Some(c + in._2) )
      case None => ( (in._1, 0), Some(in._2) )
    })ala
```

使用 Flink 的 Scala DataStream API 的一个特性 mapWithState 来实现字数统计。使用 mapWithState 时，状态描述符是隐式管理的，不能在其上设置状态 TTL。



需要避免这些情况，而是使用一些策略，使得状态最终可以释放。

* 在KeyedProcessFunction中使用计时器清除状态
* 状态描述符中设置 [State Time-To-Live](https://nightlies.apache.org/flink/flink-docs-stable/dev/stream/state/state.html#state-time-to-live-ttl) &#x20;
* 在FLink SQL中设置空闲状态保留时间（ [idle state retention time](https://nightlies.apache.org/flink/flink-docs-stable/docs/dev/table/config/#table-exec-state-ttl)）

## 怎么开启TTL

其实在 Flink DataStream API 中，TTL 功能还是比较少用的。Flink State TTL 在 Flink SQL 中是被大规模应用的，几乎除了窗口类、ETL（DWD 明细处理任务）类的任务之外，SQL 任务基本都会用到 State TTL。

### DataStream API

```javascript
@Override
public void open(Configuration parameters) throws Exception {
    super.open(parameters);

    // 使用 StateTtlConfig 开启 State TTL
    mapStateDesc.enableTimeToLive(StateTtlConfig
            .newBuilder(Time.milliseconds(1))
            .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
            .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
            .cleanupInRocksdbCompactFilter(10)
            .build());
}a
```

关于 StateTtlConfig 的每个配置项的功能如下图所示：

![](<../../../.gitbook/assets/image (7).png>)

### SQL

```java
StreamTableEnvironment
    .getConfig()
    .getConfiguration()
    .setString("table.exec.state.ttl", "180 s");
```

SQL 中 TTL 的策略不如 DataStream 那么多，SQL 中 TTL 只支持下图所示策略：

![](<../../../.gitbook/assets/image (16).png>)

## TTL基础原理

如果我们要设置 TTL 则必然需要给一条数据给一个时间戳，只有这样才能判断这条数据是否过期了。

在 Flink 中设置 State TTL，就会有这样一个时间戳，具体实现时，Flink 会把时间戳字段和具体数据字段存储作为同级存储到 State 中。

举个例子，我要将一个 String 存储到 State 中时：

1. 没有设置 State TTL 时，则直接将 String 存储在 State 中；
2. 如果设置 State TTL 时，则 Flink 会将 \<String, Long> 存储在 State 中，其中 Long 为时间戳，用于判断是否过期。



&#x20;接下来以 heap 状态后端下的 MapState 作为案例来说：

1. 如果没有设置 State TTL，则生产的 MapState 的字段类型如下（可以看到生成的就是 HeapMapState 实例）：

![](<../../../.gitbook/assets/image (17).png>)

2\. 如果设置了 State TTL，则生成的 MapState 的字段类型如下（可以看到使用到了装饰器的设计模式生成是 TtlMapState）：

![](<../../../.gitbook/assets/image (5).png>)

## TTL的4种策略

1. _**⭐ lazy 删除策略：**_就是在访问 State 的时候根据时间戳判断是否过期，如果过期则主动删除 State 数据
2. _**⭐ full snapshot cleanup 删除策略：**_从状态恢复（checkpoint、savepoint）的时候采取做过期删除，但是不支持 rocksdb 增量 ck
3. _**⭐ incremental cleanup 删除策略：**_访问 state 的时候，主动去遍历一些 state 数据判断是否过期，如果过期则主动删除 State 数据
4. _**⭐ rocksdb compaction cleanup 删除策略：**_rockdb 做 compaction 的时候遍历进行删除。仅仅支持 rocksdb

### lazy 删除策略

访问 State 的时候根据时间戳判断是否过期，如果过期则主动删除 State 数据。以 MapState 为例，如下图所示，在 MapState.get(key) 时会进行判断是否过期：

这个删除策略是不需要用户进行配置的，只要你打开了 State TTL 功能，就会默认执行。后台线程懒执行。

### full snapshot cleanup 删除策略

从状态恢复（checkpoint、savepoint）的时候采取做过期删除，但是不支持 rocksdb 增量 checkpoint。

```java
StateTtlConfig
    .newBuilder(Time.seconds(1))
    .cleanupFullSnapshot()
    .build()
```

### incremental cleanup 删除策略

访问 state 的时候，主动去遍历一些 state 数据判断是否过期，如果过期则主动删除 State 数据。

```java
StateTtlConfig
    .newBuilder(Time.seconds(1))
    // 每访问1次state，遍历 1000 条进行删除
    .cleanupIncrementally(1000, true) //True：是否也触发对每个已处理记录的清理(默认值：False)
    .build()
```

注意：

1. ⭐ 如果没有 state 访问，也没有处理数据，则不会清理过期数据。也可以选择以每个处理记录为基础进行清理，上面代码中参数true。
2. ⭐ 增量清理会增加数据处理的耗时。
3. ⭐ 现在仅 Heap state backend 支持增量清除机制。在 RocksDB state backend 上启用该特性无效。
4. ⭐ 因为是遍历删除 State 机制，并且每次遍历的条目数是固定的，所以可能会出现部分过期的 State 很长时间都过期不掉导致 Flink 任务 OOM。

### rocksdb compaction cleanup 删除策略

仅仅支持 rocksdb。在 rockdb 做 compaction 的时候遍历进行删除。

```java
StateTtlConfig
    .newBuilder(Time.seconds(1))
    // 做 compaction 时每隔 3 个 entry，重新更新一下时间戳（这个时间戳是 Flink 用于和数据中的时间戳来比较判断是否过期）
    .cleanupInRocksdbCompactFilter(3)
    .build()
```

注意：

rocksdb compaction 时调用 TTL 过滤器会降低 compaction 速度。因为 TTL 过滤器需要解析上次访问的时间戳，并对每个将参与压缩的状态进行是否过期检查。对于集合型状态类型（比如 ListState 和 MapState），会对集合中每个元素进行检查。



如果压缩无法跟上，可能需要增加 state.backend.rocsdb.thread.num。



## TTL注意事项

使用状态 TTL 会增加状态存储的消耗

不支持在event time指定 TTL

不支持向现有状态描述符添加或移除 StateTtlConfig，将导致 StateMigationException
