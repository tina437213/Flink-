# 2.2.1 keyed state

![](<../../../.gitbook/assets/image (12) (1).png>)

上图示意了keyed stream与状态存储的关系。

## 案例--去重

我们来通过一个实际案例【对流去重，仅保留每个key的第一条】来学习keyed state实现。​

```java

// Some code
private static class Event { 
  public final String key; 
  ... 
} 

public static void main(String[] args) throws Exception { 
  StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
  env.addSource(new EventSource())
    .keyBy(e -> e.key)
    .process(new Deduplicate())
    .print();
   env.execute(); 
 }
 
 public static class Deduplicate extends KeyedProcessFunction<String, Event, Event> {
  ValueState<Boolean> keyWasSeen;
​
  @Override
  public void open(Configuration conf) {
    ValueStateDescriptor<Boolean> desc = new ValueStateDescriptor<>("seen", Types.BOOLEAN);
    keyWasSeen = getRuntimeContext().getState(desc);
  }
​
  @Override
  public void processElement(Event event, Context context, Collector<Event> out) throws Exception {
    if (keyWasSeen.value() == null) {
      out.collect(event);
      keyWasSeen.update(true);
    }
  }
}
```

为了使用Flink的内置状态，我们需要：

* 使用一种Rich function
* 创建StateDescriptor，描述我们想要存储的数据
* 绑定本地定义的state变量到由Flink提供和维护的state上

### open

open()在初始化过程中被调用，此时尚未开始真正处理消息。

信息被打包成一种特定的Flink数据类型，在上面代码示例中是ValueState。ValueState是一种keyed state，意味着Flink为每个单独的key存储一个Boolean值。

这个算子的每个并行实例都会存储该实例维护一些keys的state。这是一种分片key-value存储。

### processElement

查看 processElement 方法的签名，我们发现它接收一个 Context 上下文参数。现在我们将忽略它，但是它(大多数情况下)用于实现计时器。

现在让我们看看 processElement 方法内部的业务逻辑。为了减少流的重复，我们检查是否已经看到了这个键的事件ーー即当前事件的键。

要检索状态值，我们调用. value ()方法。

要将新值存储到状态中，我们调用.update ()。

现在有一部分可能会令人困惑: 当调用 value ()和 update ()时，我们不必指定键。那么函数怎么知道当前访问的是哪个key对应的状态值？在框架调用 processElement ()方法之前，它已经自动确定了对正在处理的事件的键的作用域状态访问。

因此，重申一下: 我们已经要求 Flink 为我们管理状态，这意味着它将具有容错性，并且能够在单个实例的崩溃中存活。



## keyed state的分类

* ValueState\<T>
  * 最简单最通用的state类型，单一变量的状态，T 是某种具体的数据类型，比如 Double、String 或我们自己定义的复杂数据结构。我们可以使用 value() 方法获取状态，使用 update(value: T) 更新状态。
* ListState\<T>
  * 使用ListState\<T> 而不是ValueState\<List\<T>>，因为前者在内部做了很多优化。存储了一个由 T 类型数据组成的列表。我们可以使用 add(value: T) 或 addAll(values: java.util.List\[T]) 向状态中添加元素，使用 get(): java.lang.Iterable\[T] 获取整个列表，使用 update(values: java.util.List\[T]) 来更新列表，新的列表将替换旧的列表。
* MapState\<UK, UV>
  * 使用MapState\<UK, UV>，而不是ValueState\<HashMap\<UK,UV>>，原因同上。
  * MapState同样可以由key精准限定，这是一个嵌套Map。存储一个 Key-Value map，其功能与 Java 的 Map 几乎相同。get(key: K) 可以获取某个 key 下的 value，put(key: K, value: V) 可以对某个 key 设置 value，contains(key: K) 判断某个 key 是否存在，remove(key: K) 删除某个 key 以及对应的 value，entries(): java.lang.Iterable\[java.util.Map.Entry\[K, V]] 返回 MapState 中所有的元素，iterator(): java.util.Iterator\[java.util.Map.Entry\[K, V]] 返回一个迭代器。需要注意的是，MapState 中的 key 和 Keyed State 的 key 不是同一个 key。
  * 此类型非常有用，例如，如果我们想为KeyedStream中每个key存储一个开放式属性Hash。
  * 另一种常见的模式，在处理乱序事件时间数据时，是使用 MapState 来存储不同时间点的数据。在这些场景中，MapState 条目是一个时间戳，与该时间点相关的数据组成一对。关于这点我们后面在介绍窗口运算函数实现时会再仔细说明。
* ReducingState\<T>
  * reduce(...)内部使用
* AggregatingState\<IN, OUT>
  * aggregate(...)内部使用
* _**ReducingState\[T]、AggregatingState\[IN, OUT]、ListState\[T] 同属于 MergingState\[T]：**_与 ListState\[T] 不同的是，ReducingState\[T] 只有一个元素，而不是一个列表。它的原理是新元素通过 add(value: T) 加入后，与已有的状态元素使用 ReduceFunction 合并为一个元素，并更新到状态里。AggregatingState\[IN, OUT] 与 ReducingState\[T] 类似，也只有一个元素，只不过 AggregatingState\[IN, OUT] 的输入和输出类型可以不一样。ReducingState\[T] 和 AggregatingState\[IN, OUT] 与窗口上进行 ReduceFunction 和 AggregateFunction 很像，都是将新元素与已有元素做聚合。ReducingState 和 AggregatingState 的存在是因为它们在 Flink 的实现中很方便——应用也可直接使用。

## 状态的关键说明

![](https://files.gitbook.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FQFcuSW2F0b7byl1FZWrg%2Fuploads%2FwPyr3IV6weLv8RwwKwGI%2Fimage.png?alt=media\&token=4635b7de-f0a6-4046-87f5-3dc2d588e7be)

上图示意了keyed stream与状态存储的关系。

* ⭐ 状态适用算子：keyed-stream 后的算子使用。_**注意这里很多人会犯一个错误，就是大家会认为 keyby 后面跟的所有算子都使用的是 keyed-state，但这是错误的 ❌，比如有 keyby.process.flatmap，其中 flatmap 中使用状态的话是 operator-state**_
* ⭐ 状态的创建方式：从 context 接口获取具体的 keyed-state
* ⭐ DataStream API 中，keyed-state 提供了 ValueState、MapState、ListState 等用户接口，其中最常用 ValueState、MapState
* ⭐ 状态的存储粒度：以单 key 粒度访问、更新状态。举例，当我们使用 keyby.process，在 process 中处理逻辑时，其实每一次 process 的处理 context 都会对应到一个 key，所以在 process 中的处理都是以 key 为粒度的。_**这里很多人会犯一个错  ❌，比如想在 open 方法中访问、更新 state，这是不行的，因为 open 方法在执行时，还没有到正式的数据处理环节，上下文中是没有 key 的。**_
* ⭐ 并行度变化时：keyed-state 的重新划分是随着 key-group 进行的。其中 key-group 的个数就是最大并发度的个数。其中一个 key-group 处理一段区间 key 的数据，不同 key-group 处理的 key 是完全不同的。当任务并行度变化时，会将 key-group 重新划分到算子不同的 sub-task 上，任务启动后，任务数据在做 keyby 进行数据 shuffle 时，依然能够按照当前数据的 key 发到下游能够处理这个 key 的 key-group 中进行处理，如下图所示。_**注意：最大并行度和 key-group 的个数绑定，所以如果想恢复任务 state，最大并行度是不能修改的。大家需要提前预估最大并行度个数。**_

![](<../../../.gitbook/assets/image (4).png>)

##
