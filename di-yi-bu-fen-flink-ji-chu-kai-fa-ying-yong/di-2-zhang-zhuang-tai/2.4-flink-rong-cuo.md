# 2.4 Flink 容错

* 过State快照容错
* 精准一次
* 允许和配置Checkpointing
* Checkpoints vs. Savepoints

## State快照容错 <a href="#dtrgx" id="dtrgx"></a>

快照记录输入队列中的偏移量和整个job graph的state。这些state是数据处理在当前点产生的。

在runtime中，Flink 对作业状态进行一致的、分布式的、异步的快照。这些快照依赖于checkpoint barriers（快照屏障）。快照n的barrier被从源开始插入，并且一直贯穿到整个jobgraph。

![](<../../.gitbook/assets/image (8).png>)

当一个算子接收到所有输入的barrier n时，它会生成1个本地快照，然后把它存储在远端、持久化存储中。checkpoint是完整的，并且所有task完成了他们的备份。



## Job 生周与容错性 <a href="#wrmdx" id="wrmdx"></a>

![](<../../.gitbook/assets/image (1).png>)



当TaskManager失败了，会根据[restart strategy](https://nightlies.apache.org/flink/flink-docs-release-1.11/dev/task\_failure\_recovery.html)来进行重启。

当JobManager失败了，[JobManager High Availability](https://nightlies.apache.org/flink/flink-docs-stable/ops/jobmanager\_high\_availability.html)。TM会取消作业。依据配置情况，一个备用的或者新的JobManager。

如果用户代码中存在异常或者是 Flink 内部异常——job将失败，Flink 将取消该job，并根据选择的[restart strategy](https://nightlies.apache.org/flink/flink-docs-release-1.11/dev/task\_failure\_recovery.html)重新启动它。



## Recovery <a href="#fhin2" id="fhin2"></a>

* 重启所有的worker
* 恢复所有状态，包括输入流中的位置

![](<../../.gitbook/assets/image (2).png>)

快照策略保证的结果是整个集群状态镜像全局一致性。这意味着通常不能只重启那一个失败的worker（假设只有一个worker失败），整个集群中的所有task都必须从snapshot中的state重置它们的状态。每个worker都以协调的方式一起回滚到输入流中相同的、较早的点。

## 容错保证 <a href="#s1xe2" id="s1xe2"></a>

### 什么是精准一次？ <a href="#wa7yv" id="wa7yv"></a>

假设一个worker挂了，会发生什么？会怎么影响Flink的状态？

Exactly-once checkpointing 对正在进行的流处理有一些影响。与at least once相比，可能表现为背压或延迟增加。

### 不同级别的故障恢复 <a href="#fjmma" id="fjmma"></a>

* Deactivated checkpoints / None / At most once
  * 如果checkpoint不活跃的话，故障时，所有的state会丢失。
* At least once
  * 每个事件至少作用内部状态一次。
  * 可回放的源将被倒带和回放，但是部分event可能会被计算2次
* Exactly once
  * 每个事件只作用内部状态一次。
  * 这并不意味着每个事件只被处理1次
  * 相对于At least once，性能影响大一些
  * 故障恢复涉及倒带和重放源，确实需要重新处理输入。能够保证的是，Flink 内部状态只作用一次（或至少一次，如果用户选择较弱的保证）

### Exactly once: 端到端 <a href="#xcsbo" id="xcsbo"></a>

前面我们只是单纯的讨论了flink的state是如何影响和作用的。现在来看看全局的。

* Exactly once: 结果是对的，但是sink端可能是重复发送结果的。注意，flink中的state仍然是准确的
* Exactly once end-to-end: 结果是对的，并且结果也是不重复的。类似于金额类计算，不能接受输出重复，必须采用端到端的精准一次策略。

Exactly once和at least once 都必须保证源端数据是可回放的。

end-to-end exactly once必须保证：

* sink端是支持事务的
* 或者写操作是幂等的

举个例子：Word Count

| Configuration               | Source     | Sink                                    | What you can expect after a failure                                                                                                   |
| --------------------------- | ---------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| **no checkpointing**        | —          | —                                       | Incorrect results.                                                                                                                    |
| **at-least-once**           | replayable | —                                       | <p>No words are lost, but some are counted<br>more than once. Results are re-produced<br>after recovery (with different results).</p> |
| **exactly-once**            | replayable | —                                       | Correct results, re-produced after recovery.                                                                                          |
| **exactly-once end-to-end** | replayable | <p>transactional<br>(or idempotent)</p> | Correct results, produced once.                                                                                                       |

数据源的精准一次支持情况

source

![](<../../.gitbook/assets/image (5).png>)

sink

![](../../.gitbook/assets/image.png)

## 启用和配置checkpointing <a href="#auclu" id="auclu"></a>

* 可以在flink-conf.yaml或者用户代码中配置
* 里面有很多相关设置项，最重要的几个是：
  * checkpoints 存储在哪里
  * checkpoints被触发的机制及频率

### checkpoint存储 <a href="#qcwcv" id="qcwcv"></a>

* JobManagerCheckpointStorage(开发测试环境，非生产)
  * 默认存储在 JobManager的heap中
* FileSystemCheckpointStorage（生产）
  * checkpoints存储在分布式文件系统中
  * 推荐高可用部署
  * 需要制定一个具体的文件URI地址，要么在flink-conf.yaml，或者在用户代码中

```
state.checkpoints.dir: file:///checkpoint-dir/
或者
env.getCheckpointConfig().setCheckpointStorage("file:///checkpoint-dir");
```

### Checkpointing间隔 <a href="#dcevl" id="dcevl"></a>

* 设置间隔

execution.checkpointing.interval: 10s

env.enableCheckpointing(10000L);

* 如何考虑设置间隔
  * 集群在恢复过程中需要多长时间才能赶上
  * 对于事务型sink的消费者而言，延迟体验
  * 所涉及的运行时/内核开销

假设有一个近实时的应用，你已经设置你的checkpointing间隔相当长，类似20min。如果作业失败且需要恢复时，可能需要花费较长时间追赶到继续近实时状态，因为需要处理从最近一个checkpoint到现在为止的所有数据。

事务型sink，例如 Kafka 和 FileSink，仅提交事务作为checkpoint的一部分。因此，job输出的下游消费者将会感受到由job的checkpoint间隔控制产生的延迟。





## Snapshots, Checkpoints, and Savepoints <a href="#llrpt" id="llrpt"></a>

* Snapshots是通用术语；Checkpoints和Savepoints都是快照的一种
* 广义上讲
  * Checkpoints由Flink来管理，旨在保证容错性
  * Savepoints由用户触发并无限期保留，旨在人工操作

Savepoint 是一项可让我们为整个流应用程序生成”某个时间”点快照的能力。快照包含有关您输入源的位置信息，以及数据源读取到的偏移量信息以及整个应用程序状态信息。我们可以使用 Chandy-Lamport 算法的变体在不停止应用程序的情况下获得全部状态的一致性快照。保存点包含两个主要元素：

* 首先，Savepoint 包括一个包含（通常是很大的）二进制文件的目录，该二进制文件表示在 Savepoint和Checkpoint 生成镜像时流应用程序的整个状态
* 一个（相对较小的）元数据文件，包含指向所有文件的指针（路径），这些文件是保存点的一部分，并存储在所选的[分布式文件系统](https://cloud.tencent.com/product/chdfs?from=10680)或[数据存储](https://cloud.tencent.com/product/cdcs?from=10680)中。

### sp vs cp

![](<../../.gitbook/assets/image (6).png>)



**目标**

从概念上讲，Flink 的 Savepoint 和 Checkpoint 的不同之处很像传统[数据库](https://cloud.tencent.com/solution/database?from=10680)中备份与恢复日志之间的区别。Checkpoint 的主要目标是充当 Flink 中的恢复机制，以确保能从潜在的故障中恢复。相反，Savepoint 的主要目标是充当手动备份之后重启、恢复暂停作业的方法。

**实现**

Checkpoint 和 Savepoint 在实现上也有不同。Checkpoint 的设计轻量并快速。它们可能（但不一定必须）充分利用底层状态后端的不同功能尽可能快速地恢复数据。基于 RocksDB 的状态后端可以使用 RocksDB 的内部格式，而不是 Flink 的原生格式进行增量 Checkpoint。加速了 RocksDB 的 Checkpoint 过程，从而使它们成为更轻量级的检查点机制的一个实例。相反，Savepoint 的设计重点是数据的可移植性，并支持对作业做任何更改，这些更改会使数据的生产和恢复成本更高。

**生命周期**

Checkpoint 是自动和定期的。它们由 Flink 自动，定期地创建和删除，不需与用户进行交互，以确保在作业意外失败的情况下可以恢复。相反，Savepoint 是由用户手动创建和管理的（即，调度、创建、删除）。



#### 何时使用 Savepoint ? <a href="#3.-e4-bd-95-e6-97-b6-e4-bd-bf-e7-94-a8-savepoint" id="3.-e4-bd-95-e6-97-b6-e4-bd-bf-e7-94-a8-savepoint"></a>

尽管流处理应用程序处理的是连续产生的数据（”运动中”的数据），但在某些情况下，应用程序可能需要重新处理以前处理过的数据。Apache Flink 中的 Savepoint 允许您在以下情况下执行此操作：

* 部署新版本的流应用程序，包括上线新功能，修复Bug或更好的机器学习模型。
* 为应用程序引入 A/B 测试，使用相同的源数据流测试程序的不同版本，从相同的时间点开始测试而不用牺牲先前的状态。
* 在需要更多资源的情况下重新对应用程序扩容。
* 将流应用程序迁移到 Flink 的新版本上，或迁移到另一个集群。

## 总结 <a href="#vaw1l" id="vaw1l"></a>

* Flink可以提供（端到端的）精准一次语义保证。
* 这需要可回放的source和事务型sink
* 所有由Flink来管理的状态包括
  * keyed state
  * operator (non-keyed) state
    * source offsets
    * transaction IDs (in sinks)
    * broadcast state
  * timers



