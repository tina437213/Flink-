# 2.1 什么是状态

## 状态是普遍存在的东西

状态并不是流计算特有的概念，是生活中普遍存在的东西。

基本定义：当前计算流程需要依赖到之前计算的结果，那么之前计算的结果就是状态。

举例：

1. **状态机**：每一种当前状态，在某些条件触发下进入下一状态。
2. _**web server 应用中的状态：**_打开 github 页面，列表展示了我的归属仓库。其流程就是 web client 发给 web server 去查询我的归属仓库，web server 接收到请求之后，然后去存储引擎中进行查询匹配返回。那么存储引擎中存储的内容就是状态。
3. _**Flink 应用中的状态：**_计算最常见的 DAU 指标，那么必然需要做 id 去重，涉及到去重时，就要存储历史所有来过的的 id。

## 为什么离线里面很少提状态，实时经常提？

其实在实时计算中的状态的功能_**主要体现在任务可以做到失败重启后没有数据质量、时效问题。**_

我们来对比一下一个离线任务和实时任务的在任务失败重启时候的区别。

1. _**⭐ 离线任务失败重启：**_重新读一遍输入数据，然后重新计算一遍，没有啥大问题，大不了产出慢一些。
2. _**⭐ 实时任务失败重启：**_实时任务一般都是 7x24 小时 long run 的，挂了之后，就会有以下两个问题。首先给一个实际场景：一个消费上游 Kafka，使用 Set去重计算 DAU 的实时任务。

* _**数据质量问题：**_当这个实时任务挂了之后恢复，Set空了，这时候任务再继续从上次失败的 Offset 消费 Kafka 产出数据，则产出的数据就是错误数据了。这时候你可能会提出疑问，计算 DAU 场景的话，这个任务挂了我重新从今天 0 点开始消费 Kafka 不就得了？
* _**数据时效问题：**_我们是一个实时任务，产出的指标是有时效性（主要是时延）要求的。你可以从今天 0 点开始重新消费，但是你回溯数据也是需要时间的。举例：中午 12 点挂了，实时任务重新回溯 12 个小时的数据能在 1 分钟之内完成嘛？大多数场景下是不能的！一般都要回溯几个小时，这就是实时场景中的数据时效问题。

那当我们把状态给 _**"管理"**_ 起来时，上面的两个问题就可以迎刃而解。还是相同的计算任务、相同的业务场景：

当我们把 Set这个数据结构定期（每隔 1min）的给存储到 HDFS 上面时，任务挂了、恢复之后。我们的任务还可以从 HDFS 上面把这个数据给读回来，接着从最新的一个 Kafka Offset 继续计算就可以，这样即没有数据质量问题，也没有数据时效性问题。

## 离线任务真的是没有状态、状态管理这些个概念这个概念嘛？

离线中其实也有，举个例子 Remote Shuffle Service，比如 Spark Remote Shuffle Service。

一个常见的离线任务运行时，通常都由几个 Stage 组成，比如有 1，2，3，4，5 个 Stage 顺序执行，当第 4 个 Stage 运行挂了之后，离线任务就要从第 1 个 Stage 重新开始执行，这样的话，执行效率是非常低的。

那么这个场景下有没有办法做到第 4 个 Stage 挂了，我们只重新运行第 4 个 Stage 呢？

当然有解法，我们可以将每一个 Stage 的结果保存下来，比如第 3 个 Stage 运行完成之后，将结果保存到远程的服务，当第 4 个 Stage 任务挂了之后，只需要从远程服务将第 3 个 Stage 结果拿来重新执行就行。

而 Remote Shuffle Service 的功能就是将每一个 Stage 的运行结果存储到一个独立的 Service 上面，当第 4 个 Stage fail 之后重新恢复时，可以直接从第 4 个 Stage 开始执行。

那么这里其实也涉及到了状态的概念。对于整个任务来说，这里面的每个 Stage 的结果就是状态，Remote Shuffle Service 就起到了 _**"管理" 状态**_ 的作用。

_**实时任务真的只能依赖状态、状态管理嘛？**_

也不一定，比如无状态计算，我每次只统计1min内的统计数据，计算一个分钟级别的同时在线用户数（TUMBLE 1 min）的实时任务，在任务挂了之后，其实可以完全不依赖状态，直接从前几分钟的 Kafka Offset 去回溯一下数据也可以，能满足时效性的同时，也可以满足数据质量。
